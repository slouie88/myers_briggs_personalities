{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Initial Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "This dataset contains over 8600 rows of data, on each row is a person’s:\n",
    "- Type (This persons 4 letter MBTI code/type)\n",
    "- A section of each of the last 50 things they have posted (Each entry separated by \"|||\" (3 pipe characters))\n",
    "\n",
    "The dataset was taken from Kaggle, but the data itself was collected through the PersonalityCafe forum (http://personalitycafe.com/forum/). The purpose of this dataset is to help see if any patterns can be detected in specific types and their style of writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CSV_DATA_PATH = os.path.join(\"data\", \"mbti_1.csv\")\n",
    "\n",
    "def load_csv_data(csv_file_path: str = CSV_DATA_PATH) -> pd.DataFrame:\n",
    "    \"\"\" Load data from a given csv file into a pandas DataFrame object.\n",
    "\n",
    "    Args:\n",
    "    - csv_file_path (str) - The file path of the csv file containing the desired data to load into a pandas DataFrame object.\n",
    "\n",
    "    Returns:\n",
    "    - data (pandas.DataFrame) - The loaded data as a pandas DataFrame object.\n",
    "    \"\"\"\n",
    "    assert csv_file_path.endswith(\".csv\")\n",
    "\n",
    "    return pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_csv_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8675 entries, 0 to 8674\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   type    8675 non-null   object\n",
      " 1   posts   8675 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 135.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick check for duplicated rows\n",
    "duplication_bool_series = data.duplicated()\n",
    "duplication_bool_series.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "\n",
    "def get_online_posts_df(df: pd.DataFrame, type_col: str = \"type\", posts_col: str = \"posts\") -> pd.DataFrame:\n",
    "    \"\"\" Takes in an input pandas DataFrame, each row having a (user_personality_type, user_recent_50_comments) schema and user_recent_50_comments is a '|||' delimited string.\n",
    "    Outputs a DataFrame object where each row is a (user_personality_type, user_comment), where each row no contains exactly one comment.\n",
    "\n",
    "    Args:\n",
    "    - df (pandas.DataFrame) - The input pandas DataFrame object, where each row follows the schema (user_personality_type, user_recent_50_comments).\n",
    "    - type_col (str) - The column name of the input DataFrame's personality type column, which contains the user's personality type.\n",
    "    - posts_col (str) - The column name of the input DataFrame's posts column, which contains the user's recent 50 comments/online posts\n",
    "\n",
    "    Returns:\n",
    "    - output_df (pandas.DataFrame) - The output pandas DataFrame object, where each row follows the schema (user_personality_type, user_comment).\n",
    "    \"\"\"\n",
    "    online_posts_dict = {\n",
    "        type_col: [],\n",
    "        posts_col: []\n",
    "    }\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        personality_type = row[type_col]\n",
    "        recent_50_comments = row[posts_col].split(\"|||\")\n",
    "\n",
    "        online_posts_dict[type_col] += [personality_type] * len(recent_50_comments)\n",
    "        online_posts_dict[posts_col] += recent_50_comments\n",
    "\n",
    "    columns = online_posts_dict.keys()\n",
    "    values = list(zip_longest(*online_posts_dict.values()))\n",
    "    output_df = pd.DataFrame(values, columns=columns)\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://41.media.tumblr.com/tumblr_lfouy03PMA1q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  https://www.youtube.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://www.youtube.com/watch?v=vXZeYwwRDw8   h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ        'http://www.youtube.com/watch?v=qsXHcwe3krw\n",
       "1  INFJ  http://41.media.tumblr.com/tumblr_lfouy03PMA1q...\n",
       "2  INFJ  enfp and intj moments  https://www.youtube.com...\n",
       "3  INFJ  What has been the most life-changing experienc...\n",
       "4  INFJ  http://www.youtube.com/watch?v=vXZeYwwRDw8   h..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df = get_online_posts_df(data)\n",
    "online_posts_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering\n",
    "Since there are only two features in the given dataset (type and posts), some additional features will be engineered from the post feature's data in order to see if there is any additional insights to be gained from the data that we have.\n",
    "\n",
    "NOTE: If the \"data/mbti_2.csv\" already exists, the below code cells for the Feature Engineering section do not need to be run as there is already a local csv file that contains the newly engineered features that you can use in subsequent sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n",
      "[nltk_data]  Downloading package vader_lexicon to\n",
      "[nltk_data]      C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up nltk for work token processing.\n",
    "import nltk\n",
    "nltk.download([\"popular\", \"vader_lexicon\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering - URL Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_url_count_from_posts(df: pd.DataFrame, posts_col: str = \"posts\") -> pd.DataFrame:\n",
    "    \"\"\" Given an input pandas DataFrame that contains a column with user online posts, extract any URLs within each post.\n",
    "\n",
    "    Args:\n",
    "    - df (pandas.DataFrame) - The input DataFrame object.\n",
    "    - posts_col (str) - The name of the DataFrame column that contains the user online posts.\n",
    "\n",
    "    Returns:\n",
    "    - df (pandas.DataFrame) - The DataFrame object which contains a new column where each row contains the frequency that a URL has been mentioned for that index.\n",
    "    \"\"\"\n",
    "    regex_pattern = r\"((?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’])))\"\n",
    "    \n",
    "    df[\"url_count\"] = df[posts_col].apply(lambda x: re.findall(regex_pattern, x)).str.len()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stefa\\AppData\\Local\\Temp\\ipykernel_4548\\1752705540.py:15: DeprecationWarning: Flags not at the start of the expression '((?i)\\\\b((?:https?://' (truncated) but at position 1\n",
      "  df[\"url_count\"] = df[posts_col].apply(lambda x: re.findall(regex_pattern, x)).str.len()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>url_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://41.media.tumblr.com/tumblr_lfouy03PMA1q...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  https://www.youtube.com...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://www.youtube.com/watch?v=vXZeYwwRDw8   h...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  url_count\n",
       "0  INFJ        'http://www.youtube.com/watch?v=qsXHcwe3krw          1\n",
       "1  INFJ  http://41.media.tumblr.com/tumblr_lfouy03PMA1q...          1\n",
       "2  INFJ  enfp and intj moments  https://www.youtube.com...          2\n",
       "3  INFJ  What has been the most life-changing experienc...          0\n",
       "4  INFJ  http://www.youtube.com/watch?v=vXZeYwwRDw8   h...          2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df = extract_url_count_from_posts(online_posts_df)\n",
    "online_posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df[\"posts\"].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>url_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>422840</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I was going to close my facebook a few months ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422841</th>\n",
       "      <td>INFP</td>\n",
       "      <td>30 Seconds to Mars - All of my collections. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422842</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I have seen it, and i agree. I did actually th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422843</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Ok so i have just watched Underworld 4 (Awaken...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422844</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I would never want to turn off my emotions. so...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                              posts  url_count\n",
       "422840  INFP  I was going to close my facebook a few months ...          0\n",
       "422841  INFP  30 Seconds to Mars - All of my collections. It...          0\n",
       "422842  INFP  I have seen it, and i agree. I did actually th...          0\n",
       "422843  INFP  Ok so i have just watched Underworld 4 (Awaken...          0\n",
       "422844  INFP  I would never want to turn off my emotions. so...          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering - Noun, Verb, Adjective, Adverb, and other POS frequencies per comment/post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_online_posts_no_urls(df: pd.DataFrame, posts_col: str = \"posts\") -> pd.DataFrame:\n",
    "    \"\"\" Given an input pandas DataFrame that contains a column with user online posts, extract only non-url text from each post.\n",
    "\n",
    "    Args:\n",
    "    - df (pandas.DataFrame) - The input DataFrame object.\n",
    "    - posts_col (str) - The name of the DataFrame column that contains the user online posts.\n",
    "\n",
    "    Returns:\n",
    "    - df (pandas.DataFrame) - The DataFrame object which contains a new column where each row contains the online post without any URLs\n",
    "    \"\"\"\n",
    "    regex_pattern = r\"((?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’])))\"\n",
    "\n",
    "    df[\"posts_no_url\"] = df[posts_col].str.replace(regex_pattern, \"\").str.strip()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stefa\\AppData\\Local\\Temp\\ipykernel_4548\\2250993582.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"posts_no_url\"] = df[posts_col].str.replace(regex_pattern, \"\").str.strip()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>url_count</th>\n",
       "      <th>posts_no_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw</td>\n",
       "      <td>1</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://41.media.tumblr.com/tumblr_lfouy03PMA1q...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  https://www.youtube.com...</td>\n",
       "      <td>2</td>\n",
       "      <td>enfp and intj moments    sportscenter not top ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>0</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://www.youtube.com/watch?v=vXZeYwwRDw8   h...</td>\n",
       "      <td>2</td>\n",
       "      <td>On repeat for most of today.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  url_count  \\\n",
       "0  INFJ        'http://www.youtube.com/watch?v=qsXHcwe3krw          1   \n",
       "1  INFJ  http://41.media.tumblr.com/tumblr_lfouy03PMA1q...          1   \n",
       "2  INFJ  enfp and intj moments  https://www.youtube.com...          2   \n",
       "3  INFJ  What has been the most life-changing experienc...          0   \n",
       "4  INFJ  http://www.youtube.com/watch?v=vXZeYwwRDw8   h...          2   \n",
       "\n",
       "                                        posts_no_url  \n",
       "0                                                  '  \n",
       "1                                                     \n",
       "2  enfp and intj moments    sportscenter not top ...  \n",
       "3  What has been the most life-changing experienc...  \n",
       "4                       On repeat for most of today.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df = get_online_posts_no_urls(online_posts_df)\n",
    "online_posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    'Good one  _____   https://www.youtube.com/wat...\n",
       "101    Of course, to which I say I know; that's my bl...\n",
       "102    Does being absolutely positive that you and yo...\n",
       "103                  No, I didn't; thank you for a link!\n",
       "104    So-called Ti-Si loop (and it can stem from any...\n",
       "Name: posts, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df[\"posts\"].iloc[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Good one  _____   https://www.youtube.com/watch?v=fHiGbolFFGw\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df[\"posts\"].iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Good one  _____\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df[\"posts_no_url\"].iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag_posts(df: pd.DataFrame, posts_col: str = \"posts_no_url\") -> pd.DataFrame:\n",
    "    \"\"\" Given an input pandas DataFrame with a column of online posts, perform POS tagging on the posts and return a DataFrame with a column that contains the POS tagged posts.\n",
    "\n",
    "    Args:\n",
    "    - df (pandas.DataFrame) - The input DataFrame object.\n",
    "    - posts_col (str) - The name of the DataFrame column that contains the user online posts.\n",
    "\n",
    "    Returns:\n",
    "    - df (pandas.DataFrame) - The DataFrame object which contains a new column where each row contains the online post after POS tagging.\n",
    "    \"\"\"\n",
    "    df[\"posts_no_url_tokenized\"] = df[posts_col].str.lower().apply(nltk.word_tokenize)\n",
    "    df[\"posts_no_url_pos_tagged\"] = df[\"posts_no_url_tokenized\"].apply(nltk.pos_tag)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>url_count</th>\n",
       "      <th>posts_no_url</th>\n",
       "      <th>posts_no_url_tokenized</th>\n",
       "      <th>posts_no_url_pos_tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw</td>\n",
       "      <td>1</td>\n",
       "      <td>'</td>\n",
       "      <td>[']</td>\n",
       "      <td>[(', '')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://41.media.tumblr.com/tumblr_lfouy03PMA1q...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  https://www.youtube.com...</td>\n",
       "      <td>2</td>\n",
       "      <td>enfp and intj moments    sportscenter not top ...</td>\n",
       "      <td>[enfp, and, intj, moments, sportscenter, not, ...</td>\n",
       "      <td>[(enfp, NN), (and, CC), (intj, JJ), (moments, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>0</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>[what, has, been, the, most, life-changing, ex...</td>\n",
       "      <td>[(what, WDT), (has, VBZ), (been, VBN), (the, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://www.youtube.com/watch?v=vXZeYwwRDw8   h...</td>\n",
       "      <td>2</td>\n",
       "      <td>On repeat for most of today.</td>\n",
       "      <td>[on, repeat, for, most, of, today, .]</td>\n",
       "      <td>[(on, IN), (repeat, NN), (for, IN), (most, JJS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  url_count  \\\n",
       "0  INFJ        'http://www.youtube.com/watch?v=qsXHcwe3krw          1   \n",
       "1  INFJ  http://41.media.tumblr.com/tumblr_lfouy03PMA1q...          1   \n",
       "2  INFJ  enfp and intj moments  https://www.youtube.com...          2   \n",
       "3  INFJ  What has been the most life-changing experienc...          0   \n",
       "4  INFJ  http://www.youtube.com/watch?v=vXZeYwwRDw8   h...          2   \n",
       "\n",
       "                                        posts_no_url  \\\n",
       "0                                                  '   \n",
       "1                                                      \n",
       "2  enfp and intj moments    sportscenter not top ...   \n",
       "3  What has been the most life-changing experienc...   \n",
       "4                       On repeat for most of today.   \n",
       "\n",
       "                              posts_no_url_tokenized  \\\n",
       "0                                                [']   \n",
       "1                                                 []   \n",
       "2  [enfp, and, intj, moments, sportscenter, not, ...   \n",
       "3  [what, has, been, the, most, life-changing, ex...   \n",
       "4              [on, repeat, for, most, of, today, .]   \n",
       "\n",
       "                             posts_no_url_pos_tagged  \n",
       "0                                          [(', '')]  \n",
       "1                                                 []  \n",
       "2  [(enfp, NN), (and, CC), (intj, JJ), (moments, ...  \n",
       "3  [(what, WDT), (has, VBZ), (been, VBN), (the, D...  \n",
       "4  [(on, IN), (repeat, NN), (for, IN), (most, JJS...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df = pos_tag_posts(online_posts_df)\n",
    "online_posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enfp', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('intj', 'JJ'),\n",
       " ('moments', 'NNS'),\n",
       " ('sportscenter', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('top', 'VB'),\n",
       " ('ten', 'NN'),\n",
       " ('plays', 'NNS'),\n",
       " ('pranks', 'NNS')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df[\"posts_no_url_pos_tagged\"].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pos_count_features(df: pd.DataFrame, pos_tagged_tokens_col: str = \"posts_no_url_pos_tagged\") -> pd.DataFrame:\n",
    "    \"\"\" Given an input pandas DataFrame that contains a column that holds tokenized posts and their POS (part-of-speech tags), add frequency count featured of the following POS tags for each row:\n",
    "        - Nouns\n",
    "        - Verbs\n",
    "        - Cardinal Digits\n",
    "        - Adjectives\n",
    "        - Adverbs\n",
    "        - Prepositions\n",
    "        - Interjections\n",
    "        - Determiners\n",
    "\n",
    "    Args:\n",
    "    - df (pandas.DataFrame) - the input pandas DataFrame\n",
    "    - pos_tagged_tokens_col (str) - the name of the column of the input df that holds the pos tagged tokens to use for calculating freqeuncy of a part-of-speech per comment/post/row.\n",
    "\n",
    "    Returns:\n",
    "    - df(pandas.DataFrame) - the input pandas DataFrame, but with the newly added features/columns.\n",
    "    \"\"\"\n",
    "    df[\"noun_freq\"] = df[pos_tagged_tokens_col].apply(lambda x: len([word for word, tag in x if tag in ['NN', 'NNS', 'NNP', 'NNPS']]))\n",
    "    df[\"verb_freq\"] = df[pos_tagged_tokens_col].apply(lambda x: len([word for word, tag in x if tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']]))\n",
    "    df[\"cardinal_digits_freq\"] = df[pos_tagged_tokens_col].apply(lambda x: len([word for word, tag in x if tag in ['CD']]))\n",
    "    df[\"adjective_freq\"] = df[pos_tagged_tokens_col].apply(lambda x: len([word for word, tag in x if tag in ['JJ', 'JJR', 'JJS']]))\n",
    "    df[\"adverb_freq\"] = df[pos_tagged_tokens_col].apply(lambda x: len([word for word, tag in x if tag in ['RB', 'RBR', 'RBS', 'WRB']]))\n",
    "    df[\"preposition_freq\"] = df[pos_tagged_tokens_col].apply(lambda x: len([word for word, tag in x if tag in ['IN']]))\n",
    "    df[\"interjection_freq\"] = df[pos_tagged_tokens_col].apply(lambda x: len([word for word, tag in x if tag in ['UH']]))\n",
    "    df[\"determiner_freq\"] = df[pos_tagged_tokens_col].apply(lambda x: len([word for word, tag in x if tag in ['DT', 'WDT']]))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>url_count</th>\n",
       "      <th>noun_freq</th>\n",
       "      <th>verb_freq</th>\n",
       "      <th>cardinal_digits_freq</th>\n",
       "      <th>adjective_freq</th>\n",
       "      <th>adverb_freq</th>\n",
       "      <th>preposition_freq</th>\n",
       "      <th>interjection_freq</th>\n",
       "      <th>determiner_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://41.media.tumblr.com/tumblr_lfouy03PMA1q...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  https://www.youtube.com...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://www.youtube.com/watch?v=vXZeYwwRDw8   h...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  url_count  \\\n",
       "0  INFJ        'http://www.youtube.com/watch?v=qsXHcwe3krw          1   \n",
       "1  INFJ  http://41.media.tumblr.com/tumblr_lfouy03PMA1q...          1   \n",
       "2  INFJ  enfp and intj moments  https://www.youtube.com...          2   \n",
       "3  INFJ  What has been the most life-changing experienc...          0   \n",
       "4  INFJ  http://www.youtube.com/watch?v=vXZeYwwRDw8   h...          2   \n",
       "\n",
       "   noun_freq  verb_freq  cardinal_digits_freq  adjective_freq  adverb_freq  \\\n",
       "0          0          0                     0               0            0   \n",
       "1          0          0                     0               0            0   \n",
       "2          5          1                     0               1            1   \n",
       "3          2          2                     0               1            1   \n",
       "4          2          0                     0               1            0   \n",
       "\n",
       "   preposition_freq  interjection_freq  determiner_freq  \n",
       "0                 0                  0                0  \n",
       "1                 0                  0                0  \n",
       "2                 0                  0                0  \n",
       "3                 1                  0                2  \n",
       "4                 3                  0                0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df = add_pos_count_features(online_posts_df)\n",
    "online_posts_df[[\"type\", \"posts\", \"url_count\", \"noun_freq\", \"verb_freq\", \"cardinal_digits_freq\", \"adjective_freq\", \"adverb_freq\", \"preposition_freq\", \"interjection_freq\", \"determiner_freq\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>url_count</th>\n",
       "      <th>noun_freq</th>\n",
       "      <th>verb_freq</th>\n",
       "      <th>cardinal_digits_freq</th>\n",
       "      <th>adjective_freq</th>\n",
       "      <th>adverb_freq</th>\n",
       "      <th>preposition_freq</th>\n",
       "      <th>interjection_freq</th>\n",
       "      <th>determiner_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>422840</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I was going to close my facebook a few months ...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422841</th>\n",
       "      <td>INFP</td>\n",
       "      <td>30 Seconds to Mars - All of my collections. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422842</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I have seen it, and i agree. I did actually th...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422843</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Ok so i have just watched Underworld 4 (Awaken...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422844</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I would never want to turn off my emotions. so...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                              posts  url_count  \\\n",
       "422840  INFP  I was going to close my facebook a few months ...          0   \n",
       "422841  INFP  30 Seconds to Mars - All of my collections. It...          0   \n",
       "422842  INFP  I have seen it, and i agree. I did actually th...          0   \n",
       "422843  INFP  Ok so i have just watched Underworld 4 (Awaken...          0   \n",
       "422844  INFP  I would never want to turn off my emotions. so...          0   \n",
       "\n",
       "        noun_freq  verb_freq  cardinal_digits_freq  adjective_freq  \\\n",
       "422840          9         10                     0               4   \n",
       "422841          3          4                     1               0   \n",
       "422842          7         11                     0               2   \n",
       "422843          4          9                     2               8   \n",
       "422844          4          4                     0               1   \n",
       "\n",
       "        adverb_freq  preposition_freq  interjection_freq  determiner_freq  \n",
       "422840            3                 3                  0                2  \n",
       "422841            2                 1                  0                1  \n",
       "422842            5                 3                  0                3  \n",
       "422843            6                 3                  0                4  \n",
       "422844            3                 2                  0                1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df[[\"type\", \"posts\", \"url_count\", \"noun_freq\", \"verb_freq\", \"cardinal_digits_freq\", \"adjective_freq\", \"adverb_freq\", \"preposition_freq\", \"interjection_freq\", \"determiner_freq\"]].tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering - Sentiment per comment/post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def add_sentiment_score_features(df: pd.DataFrame, posts_col: str = \"posts\") -> pd.DataFrame:\n",
    "    \"\"\" Given an input pandas DataFrame which contains a column that holds online comments posted by users of particular MBTI personality types, add the sentiment scores of those comments as new features to the DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - df (pandas.DataFrame) - The input pandas DataFrame object.\n",
    "    - posts_col (str) - The name of the column that contains the online comments.\n",
    "\n",
    "    Returns:\n",
    "    - df (pandas.DataFrame) - The pandas DataFrame object with the newly added sentiment score features.\n",
    "    \"\"\"\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    df[\"negative_sentiment\"] = df[posts_col].apply(lambda x: sia.polarity_scores(x)[\"neg\"])\n",
    "    df[\"neutral_sentiment\"] = df[posts_col].apply(lambda x: sia.polarity_scores(x)[\"neu\"])\n",
    "    df[\"positive_sentiment\"] = df[posts_col].apply(lambda x: sia.polarity_scores(x)[\"pos\"])\n",
    "    df[\"overall_sentiment\"] = df[posts_col].apply(lambda x: sia.polarity_scores(x)[\"compound\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>url_count</th>\n",
       "      <th>noun_freq</th>\n",
       "      <th>verb_freq</th>\n",
       "      <th>cardinal_digits_freq</th>\n",
       "      <th>adjective_freq</th>\n",
       "      <th>adverb_freq</th>\n",
       "      <th>preposition_freq</th>\n",
       "      <th>interjection_freq</th>\n",
       "      <th>determiner_freq</th>\n",
       "      <th>negative_sentiment</th>\n",
       "      <th>neutral_sentiment</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://41.media.tumblr.com/tumblr_lfouy03PMA1q...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  https://www.youtube.com...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://www.youtube.com/watch?v=vXZeYwwRDw8   h...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  url_count  \\\n",
       "0  INFJ        'http://www.youtube.com/watch?v=qsXHcwe3krw          1   \n",
       "1  INFJ  http://41.media.tumblr.com/tumblr_lfouy03PMA1q...          1   \n",
       "2  INFJ  enfp and intj moments  https://www.youtube.com...          2   \n",
       "3  INFJ  What has been the most life-changing experienc...          0   \n",
       "4  INFJ  http://www.youtube.com/watch?v=vXZeYwwRDw8   h...          2   \n",
       "\n",
       "   noun_freq  verb_freq  cardinal_digits_freq  adjective_freq  adverb_freq  \\\n",
       "0          0          0                     0               0            0   \n",
       "1          0          0                     0               0            0   \n",
       "2          5          1                     0               1            1   \n",
       "3          2          2                     0               1            1   \n",
       "4          2          0                     0               1            0   \n",
       "\n",
       "   preposition_freq  interjection_freq  determiner_freq  negative_sentiment  \\\n",
       "0                 0                  0                0                0.00   \n",
       "1                 0                  0                0                0.00   \n",
       "2                 0                  0                0                0.27   \n",
       "3                 1                  0                2                0.00   \n",
       "4                 3                  0                0                0.00   \n",
       "\n",
       "   neutral_sentiment  positive_sentiment  overall_sentiment  \n",
       "0               1.00                 0.0             0.0000  \n",
       "1               1.00                 0.0             0.0000  \n",
       "2               0.73                 0.0            -0.4003  \n",
       "3               1.00                 0.0             0.0000  \n",
       "4               1.00                 0.0             0.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df = add_sentiment_score_features(online_posts_df)\n",
    "online_posts_df[[\n",
    "    \"type\", \n",
    "    \"posts\", \n",
    "    \"url_count\", \n",
    "    \"noun_freq\", \n",
    "    \"verb_freq\", \n",
    "    \"cardinal_digits_freq\", \n",
    "    \"adjective_freq\", \n",
    "    \"adverb_freq\", \n",
    "    \"preposition_freq\",\n",
    "    \"interjection_freq\",\n",
    "    \"determiner_freq\",\n",
    "    \"negative_sentiment\",\n",
    "    \"neutral_sentiment\",\n",
    "    \"positive_sentiment\",\n",
    "    \"overall_sentiment\"\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>url_count</th>\n",
       "      <th>noun_freq</th>\n",
       "      <th>verb_freq</th>\n",
       "      <th>cardinal_digits_freq</th>\n",
       "      <th>adjective_freq</th>\n",
       "      <th>adverb_freq</th>\n",
       "      <th>preposition_freq</th>\n",
       "      <th>interjection_freq</th>\n",
       "      <th>determiner_freq</th>\n",
       "      <th>negative_sentiment</th>\n",
       "      <th>neutral_sentiment</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>422840</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I was going to close my facebook a few months ...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.7783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422841</th>\n",
       "      <td>INFP</td>\n",
       "      <td>30 Seconds to Mars - All of my collections. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422842</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I have seen it, and i agree. I did actually th...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422843</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Ok so i have just watched Underworld 4 (Awaken...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.8218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422844</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I would never want to turn off my emotions. so...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.1182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                              posts  url_count  \\\n",
       "422840  INFP  I was going to close my facebook a few months ...          0   \n",
       "422841  INFP  30 Seconds to Mars - All of my collections. It...          0   \n",
       "422842  INFP  I have seen it, and i agree. I did actually th...          0   \n",
       "422843  INFP  Ok so i have just watched Underworld 4 (Awaken...          0   \n",
       "422844  INFP  I would never want to turn off my emotions. so...          0   \n",
       "\n",
       "        noun_freq  verb_freq  cardinal_digits_freq  adjective_freq  \\\n",
       "422840          9         10                     0               4   \n",
       "422841          3          4                     1               0   \n",
       "422842          7         11                     0               2   \n",
       "422843          4          9                     2               8   \n",
       "422844          4          4                     0               1   \n",
       "\n",
       "        adverb_freq  preposition_freq  interjection_freq  determiner_freq  \\\n",
       "422840            3                 3                  0                2   \n",
       "422841            2                 1                  0                1   \n",
       "422842            5                 3                  0                3   \n",
       "422843            6                 3                  0                4   \n",
       "422844            3                 2                  0                1   \n",
       "\n",
       "        negative_sentiment  neutral_sentiment  positive_sentiment  \\\n",
       "422840                0.00              0.829               0.171   \n",
       "422841                0.00              1.000               0.000   \n",
       "422842                0.00              0.928               0.072   \n",
       "422843                0.00              0.798               0.202   \n",
       "422844                0.12              0.880               0.000   \n",
       "\n",
       "        overall_sentiment  \n",
       "422840             0.7783  \n",
       "422841             0.0000  \n",
       "422842             0.3612  \n",
       "422843             0.8218  \n",
       "422844            -0.1182  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df[[\n",
    "    \"type\", \n",
    "    \"posts\", \n",
    "    \"url_count\", \n",
    "    \"noun_freq\", \n",
    "    \"verb_freq\", \n",
    "    \"cardinal_digits_freq\", \n",
    "    \"adjective_freq\", \n",
    "    \"adverb_freq\", \n",
    "    \"preposition_freq\",\n",
    "    \"interjection_freq\",\n",
    "    \"determiner_freq\",\n",
    "    \"negative_sentiment\",\n",
    "    \"neutral_sentiment\",\n",
    "    \"positive_sentiment\",\n",
    "    \"overall_sentiment\"\n",
    "]].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def add_word_count_feature(df: pd.DataFrame, posts_col: str = \"posts_no_url_tokenized\"):\n",
    "    \"\"\" Given an input pandas DataFrame which contains a column that holds tokenized online comments posted by users of particular MBTI personality types without urls, add the word count for each comment/post.\n",
    "\n",
    "    Args:\n",
    "    - df (pandas.DataFrame) - The input pandas DataFrame object.\n",
    "    - posts_col (str) - The name of the column that contains the tokenized online comments without urls.\n",
    "\n",
    "    Returns:\n",
    "    - df (pandas.DataFrame) - The pandas DataFrame object with the newly added sentiment score features.\n",
    "    \"\"\"\n",
    "    df[\"word_count\"] = df[posts_col].apply(lambda x: len([word for word in x if not word in string.punctuation]))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>url_count</th>\n",
       "      <th>noun_freq</th>\n",
       "      <th>verb_freq</th>\n",
       "      <th>cardinal_digits_freq</th>\n",
       "      <th>adjective_freq</th>\n",
       "      <th>adverb_freq</th>\n",
       "      <th>preposition_freq</th>\n",
       "      <th>interjection_freq</th>\n",
       "      <th>determiner_freq</th>\n",
       "      <th>negative_sentiment</th>\n",
       "      <th>neutral_sentiment</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>overall_sentiment</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://41.media.tumblr.com/tumblr_lfouy03PMA1q...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  https://www.youtube.com...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4003</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://www.youtube.com/watch?v=vXZeYwwRDw8   h...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  url_count  \\\n",
       "0  INFJ        'http://www.youtube.com/watch?v=qsXHcwe3krw          1   \n",
       "1  INFJ  http://41.media.tumblr.com/tumblr_lfouy03PMA1q...          1   \n",
       "2  INFJ  enfp and intj moments  https://www.youtube.com...          2   \n",
       "3  INFJ  What has been the most life-changing experienc...          0   \n",
       "4  INFJ  http://www.youtube.com/watch?v=vXZeYwwRDw8   h...          2   \n",
       "\n",
       "   noun_freq  verb_freq  cardinal_digits_freq  adjective_freq  adverb_freq  \\\n",
       "0          0          0                     0               0            0   \n",
       "1          0          0                     0               0            0   \n",
       "2          5          1                     0               1            1   \n",
       "3          2          2                     0               1            1   \n",
       "4          2          0                     0               1            0   \n",
       "\n",
       "   preposition_freq  interjection_freq  determiner_freq  negative_sentiment  \\\n",
       "0                 0                  0                0                0.00   \n",
       "1                 0                  0                0                0.00   \n",
       "2                 0                  0                0                0.27   \n",
       "3                 1                  0                2                0.00   \n",
       "4                 3                  0                0                0.00   \n",
       "\n",
       "   neutral_sentiment  positive_sentiment  overall_sentiment  word_count  \n",
       "0               1.00                 0.0             0.0000           0  \n",
       "1               1.00                 0.0             0.0000           0  \n",
       "2               0.73                 0.0            -0.4003          10  \n",
       "3               1.00                 0.0             0.0000          10  \n",
       "4               1.00                 0.0             0.0000           6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df = add_word_count_feature(online_posts_df)\n",
    "online_posts_df[[\n",
    "    \"type\", \n",
    "    \"posts\", \n",
    "    \"url_count\", \n",
    "    \"noun_freq\", \n",
    "    \"verb_freq\", \n",
    "    \"cardinal_digits_freq\", \n",
    "    \"adjective_freq\", \n",
    "    \"adverb_freq\", \n",
    "    \"preposition_freq\",\n",
    "    \"interjection_freq\",\n",
    "    \"determiner_freq\",\n",
    "    \"negative_sentiment\",\n",
    "    \"neutral_sentiment\",\n",
    "    \"positive_sentiment\",\n",
    "    \"overall_sentiment\",\n",
    "    \"word_count\"\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>url_count</th>\n",
       "      <th>noun_freq</th>\n",
       "      <th>verb_freq</th>\n",
       "      <th>cardinal_digits_freq</th>\n",
       "      <th>adjective_freq</th>\n",
       "      <th>adverb_freq</th>\n",
       "      <th>preposition_freq</th>\n",
       "      <th>interjection_freq</th>\n",
       "      <th>determiner_freq</th>\n",
       "      <th>negative_sentiment</th>\n",
       "      <th>neutral_sentiment</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>overall_sentiment</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>422840</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I was going to close my facebook a few months ...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422841</th>\n",
       "      <td>INFP</td>\n",
       "      <td>30 Seconds to Mars - All of my collections. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422842</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I have seen it, and i agree. I did actually th...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422843</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Ok so i have just watched Underworld 4 (Awaken...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.8218</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422844</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I would never want to turn off my emotions. so...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.1182</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                              posts  url_count  \\\n",
       "422840  INFP  I was going to close my facebook a few months ...          0   \n",
       "422841  INFP  30 Seconds to Mars - All of my collections. It...          0   \n",
       "422842  INFP  I have seen it, and i agree. I did actually th...          0   \n",
       "422843  INFP  Ok so i have just watched Underworld 4 (Awaken...          0   \n",
       "422844  INFP  I would never want to turn off my emotions. so...          0   \n",
       "\n",
       "        noun_freq  verb_freq  cardinal_digits_freq  adjective_freq  \\\n",
       "422840          9         10                     0               4   \n",
       "422841          3          4                     1               0   \n",
       "422842          7         11                     0               2   \n",
       "422843          4          9                     2               8   \n",
       "422844          4          4                     0               1   \n",
       "\n",
       "        adverb_freq  preposition_freq  interjection_freq  determiner_freq  \\\n",
       "422840            3                 3                  0                2   \n",
       "422841            2                 1                  0                1   \n",
       "422842            5                 3                  0                3   \n",
       "422843            6                 3                  0                4   \n",
       "422844            3                 2                  0                1   \n",
       "\n",
       "        negative_sentiment  neutral_sentiment  positive_sentiment  \\\n",
       "422840                0.00              0.829               0.171   \n",
       "422841                0.00              1.000               0.000   \n",
       "422842                0.00              0.928               0.072   \n",
       "422843                0.00              0.798               0.202   \n",
       "422844                0.12              0.880               0.000   \n",
       "\n",
       "        overall_sentiment  word_count  \n",
       "422840             0.7783          41  \n",
       "422841             0.0000          17  \n",
       "422842             0.3612          39  \n",
       "422843             0.8218          43  \n",
       "422844            -0.1182          23  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df[[\n",
    "    \"type\", \n",
    "    \"posts\", \n",
    "    \"url_count\", \n",
    "    \"noun_freq\", \n",
    "    \"verb_freq\", \n",
    "    \"cardinal_digits_freq\", \n",
    "    \"adjective_freq\", \n",
    "    \"adverb_freq\", \n",
    "    \"preposition_freq\",\n",
    "    \"interjection_freq\",\n",
    "    \"determiner_freq\",\n",
    "    \"negative_sentiment\",\n",
    "    \"neutral_sentiment\",\n",
    "    \"positive_sentiment\",\n",
    "    \"overall_sentiment\",\n",
    "    \"word_count\"\n",
    "]].tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following new features have been engineered from executing the feature engineering code cells above:\n",
    "- Number of URLs per comment/post\n",
    "- Number of nouns per comment/post\n",
    "- Number of verbs per comment/post\n",
    "- Number of cardinal digits (mentions of a number) per comment/post\n",
    "- Number of adjectives per comment/post\n",
    "- Number of adverbs per comment/post\n",
    "- Number of prepositions per comment/post\n",
    "- Number of interjections per comment/post\n",
    "- Number of determiners per comment/post\n",
    "- Overall Sentiment Score per comment/post\n",
    "- Number of words used per comment/post"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Analysis Preparation\n",
    "Preparation for data analysis by merging the DataFrame with the newly engineered features together with the individual personality factors of each post's author's personality type and writing to a csv file locally. This is done so the above code cells don't have to be run every single time to run the data analysis code cells that will be below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_personality_factors(personality_dataset: pd.DataFrame, personalities_col_name: str = \"type\") -> dict:\n",
    "    \"\"\" Return a dictionary containing the personality factors from the given pandas DataFrame containing Myers Briggs personalities.\n",
    "\n",
    "    Args:\n",
    "    - personality_dataset (pandas.DataFrame) - The pandas DataFrame object containing the Myers Briggs personalities data.\n",
    "    - personalities_col_name (str) - The name of the column which contains the Myers Briggs personalities in the given DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - personality_factors_dict (dict) - A dictionary containing the number personality factors, split into Extraversion vs Introversion, Sensing vs Intuition, Thinking vs Feeling, Judging vs Perceiving.\n",
    "    \"\"\"\n",
    "    personality_factors_dict = {\n",
    "        \"e_vs_i\": [],\n",
    "        \"s_vs_n\": [],\n",
    "        \"t_vs_f\": [],\n",
    "        \"j_vs_p\": []\n",
    "    }\n",
    "\n",
    "    for index, row in personality_dataset.iterrows():\n",
    "        personality_type_str = row[personalities_col_name]\n",
    "        e_vs_i = personality_type_str[0]\n",
    "        s_vs_n = personality_type_str[1]\n",
    "        t_vs_f = personality_type_str[2]\n",
    "        j_vs_p = personality_type_str[3]\n",
    "\n",
    "        personality_factors_dict[\"e_vs_i\"].append(e_vs_i)\n",
    "        personality_factors_dict[\"s_vs_n\"].append(s_vs_n)\n",
    "        personality_factors_dict[\"t_vs_f\"].append(t_vs_f)\n",
    "        personality_factors_dict[\"j_vs_p\"].append(j_vs_p)\n",
    "\n",
    "    return personality_factors_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_vs_i</th>\n",
       "      <th>s_vs_n</th>\n",
       "      <th>t_vs_f</th>\n",
       "      <th>j_vs_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  e_vs_i s_vs_n t_vs_f j_vs_p\n",
       "0      I      N      F      J\n",
       "1      I      N      F      J\n",
       "2      I      N      F      J\n",
       "3      I      N      F      J\n",
       "4      I      N      F      J"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "personality_factors_per_post_dict = get_personality_factors(online_posts_df)\n",
    "columns = personality_factors_per_post_dict.keys()\n",
    "values = list(zip_longest(*personality_factors_per_post_dict.values()))\n",
    "personality_factors_per_post = pd.DataFrame(values, columns=columns)\n",
    "personality_factors_per_post.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_vs_i</th>\n",
       "      <th>s_vs_n</th>\n",
       "      <th>t_vs_f</th>\n",
       "      <th>j_vs_p</th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>url_count</th>\n",
       "      <th>posts_no_url</th>\n",
       "      <th>posts_no_url_tokenized</th>\n",
       "      <th>posts_no_url_pos_tagged</th>\n",
       "      <th>...</th>\n",
       "      <th>adjective_freq</th>\n",
       "      <th>adverb_freq</th>\n",
       "      <th>preposition_freq</th>\n",
       "      <th>interjection_freq</th>\n",
       "      <th>determiner_freq</th>\n",
       "      <th>negative_sentiment</th>\n",
       "      <th>neutral_sentiment</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>overall_sentiment</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw</td>\n",
       "      <td>1</td>\n",
       "      <td>'</td>\n",
       "      <td>[']</td>\n",
       "      <td>[(', '')]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://41.media.tumblr.com/tumblr_lfouy03PMA1q...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  https://www.youtube.com...</td>\n",
       "      <td>2</td>\n",
       "      <td>enfp and intj moments    sportscenter not top ...</td>\n",
       "      <td>[enfp, and, intj, moments, sportscenter, not, ...</td>\n",
       "      <td>[(enfp, NN), (and, CC), (intj, JJ), (moments, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4003</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>0</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>[what, has, been, the, most, life-changing, ex...</td>\n",
       "      <td>[(what, WDT), (has, VBZ), (been, VBN), (the, D...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://www.youtube.com/watch?v=vXZeYwwRDw8   h...</td>\n",
       "      <td>2</td>\n",
       "      <td>On repeat for most of today.</td>\n",
       "      <td>[on, repeat, for, most, of, today, .]</td>\n",
       "      <td>[(on, IN), (repeat, NN), (for, IN), (most, JJS...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  e_vs_i s_vs_n t_vs_f j_vs_p  type  \\\n",
       "0      I      N      F      J  INFJ   \n",
       "1      I      N      F      J  INFJ   \n",
       "2      I      N      F      J  INFJ   \n",
       "3      I      N      F      J  INFJ   \n",
       "4      I      N      F      J  INFJ   \n",
       "\n",
       "                                               posts  url_count  \\\n",
       "0        'http://www.youtube.com/watch?v=qsXHcwe3krw          1   \n",
       "1  http://41.media.tumblr.com/tumblr_lfouy03PMA1q...          1   \n",
       "2  enfp and intj moments  https://www.youtube.com...          2   \n",
       "3  What has been the most life-changing experienc...          0   \n",
       "4  http://www.youtube.com/watch?v=vXZeYwwRDw8   h...          2   \n",
       "\n",
       "                                        posts_no_url  \\\n",
       "0                                                  '   \n",
       "1                                                      \n",
       "2  enfp and intj moments    sportscenter not top ...   \n",
       "3  What has been the most life-changing experienc...   \n",
       "4                       On repeat for most of today.   \n",
       "\n",
       "                              posts_no_url_tokenized  \\\n",
       "0                                                [']   \n",
       "1                                                 []   \n",
       "2  [enfp, and, intj, moments, sportscenter, not, ...   \n",
       "3  [what, has, been, the, most, life-changing, ex...   \n",
       "4              [on, repeat, for, most, of, today, .]   \n",
       "\n",
       "                             posts_no_url_pos_tagged  ...  adjective_freq  \\\n",
       "0                                          [(', '')]  ...               0   \n",
       "1                                                 []  ...               0   \n",
       "2  [(enfp, NN), (and, CC), (intj, JJ), (moments, ...  ...               1   \n",
       "3  [(what, WDT), (has, VBZ), (been, VBN), (the, D...  ...               1   \n",
       "4  [(on, IN), (repeat, NN), (for, IN), (most, JJS...  ...               1   \n",
       "\n",
       "   adverb_freq  preposition_freq  interjection_freq  determiner_freq  \\\n",
       "0            0                 0                  0                0   \n",
       "1            0                 0                  0                0   \n",
       "2            1                 0                  0                0   \n",
       "3            1                 1                  0                2   \n",
       "4            0                 3                  0                0   \n",
       "\n",
       "   negative_sentiment  neutral_sentiment  positive_sentiment  \\\n",
       "0                0.00               1.00                 0.0   \n",
       "1                0.00               1.00                 0.0   \n",
       "2                0.27               0.73                 0.0   \n",
       "3                0.00               1.00                 0.0   \n",
       "4                0.00               1.00                 0.0   \n",
       "\n",
       "   overall_sentiment  word_count  \n",
       "0             0.0000           0  \n",
       "1             0.0000           0  \n",
       "2            -0.4003          10  \n",
       "3             0.0000          10  \n",
       "4             0.0000           6  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df_merged = pd.concat([personality_factors_per_post, online_posts_df], axis=1)\n",
    "online_posts_df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_vs_i</th>\n",
       "      <th>s_vs_n</th>\n",
       "      <th>t_vs_f</th>\n",
       "      <th>j_vs_p</th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>url_count</th>\n",
       "      <th>posts_no_url</th>\n",
       "      <th>posts_no_url_tokenized</th>\n",
       "      <th>posts_no_url_pos_tagged</th>\n",
       "      <th>...</th>\n",
       "      <th>adjective_freq</th>\n",
       "      <th>adverb_freq</th>\n",
       "      <th>preposition_freq</th>\n",
       "      <th>interjection_freq</th>\n",
       "      <th>determiner_freq</th>\n",
       "      <th>negative_sentiment</th>\n",
       "      <th>neutral_sentiment</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>overall_sentiment</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>422840</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>INFP</td>\n",
       "      <td>I was going to close my facebook a few months ...</td>\n",
       "      <td>0</td>\n",
       "      <td>I was going to close my facebook a few months ...</td>\n",
       "      <td>[i, was, going, to, close, my, facebook, a, fe...</td>\n",
       "      <td>[(i, NN), (was, VBD), (going, VBG), (to, TO), ...</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422841</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>INFP</td>\n",
       "      <td>30 Seconds to Mars - All of my collections. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>30 Seconds to Mars - All of my collections. It...</td>\n",
       "      <td>[30, seconds, to, mars, -, all, of, my, collec...</td>\n",
       "      <td>[(30, CD), (seconds, NNS), (to, TO), (mars, VB...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422842</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>INFP</td>\n",
       "      <td>I have seen it, and i agree. I did actually th...</td>\n",
       "      <td>0</td>\n",
       "      <td>I have seen it, and i agree. I did actually th...</td>\n",
       "      <td>[i, have, seen, it, ,, and, i, agree, ., i, di...</td>\n",
       "      <td>[(i, NNS), (have, VBP), (seen, VBN), (it, PRP)...</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422843</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>INFP</td>\n",
       "      <td>Ok so i have just watched Underworld 4 (Awaken...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ok so i have just watched Underworld 4 (Awaken...</td>\n",
       "      <td>[ok, so, i, have, just, watched, underworld, 4...</td>\n",
       "      <td>[(ok, IN), (so, RB), (i, JJ), (have, VBP), (ju...</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.8218</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422844</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>INFP</td>\n",
       "      <td>I would never want to turn off my emotions. so...</td>\n",
       "      <td>0</td>\n",
       "      <td>I would never want to turn off my emotions. so...</td>\n",
       "      <td>[i, would, never, want, to, turn, off, my, emo...</td>\n",
       "      <td>[(i, NN), (would, MD), (never, RB), (want, VB)...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.1182</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       e_vs_i s_vs_n t_vs_f j_vs_p  type  \\\n",
       "422840      I      N      F      P  INFP   \n",
       "422841      I      N      F      P  INFP   \n",
       "422842      I      N      F      P  INFP   \n",
       "422843      I      N      F      P  INFP   \n",
       "422844      I      N      F      P  INFP   \n",
       "\n",
       "                                                    posts  url_count  \\\n",
       "422840  I was going to close my facebook a few months ...          0   \n",
       "422841  30 Seconds to Mars - All of my collections. It...          0   \n",
       "422842  I have seen it, and i agree. I did actually th...          0   \n",
       "422843  Ok so i have just watched Underworld 4 (Awaken...          0   \n",
       "422844  I would never want to turn off my emotions. so...          0   \n",
       "\n",
       "                                             posts_no_url  \\\n",
       "422840  I was going to close my facebook a few months ...   \n",
       "422841  30 Seconds to Mars - All of my collections. It...   \n",
       "422842  I have seen it, and i agree. I did actually th...   \n",
       "422843  Ok so i have just watched Underworld 4 (Awaken...   \n",
       "422844  I would never want to turn off my emotions. so...   \n",
       "\n",
       "                                   posts_no_url_tokenized  \\\n",
       "422840  [i, was, going, to, close, my, facebook, a, fe...   \n",
       "422841  [30, seconds, to, mars, -, all, of, my, collec...   \n",
       "422842  [i, have, seen, it, ,, and, i, agree, ., i, di...   \n",
       "422843  [ok, so, i, have, just, watched, underworld, 4...   \n",
       "422844  [i, would, never, want, to, turn, off, my, emo...   \n",
       "\n",
       "                                  posts_no_url_pos_tagged  ...  \\\n",
       "422840  [(i, NN), (was, VBD), (going, VBG), (to, TO), ...  ...   \n",
       "422841  [(30, CD), (seconds, NNS), (to, TO), (mars, VB...  ...   \n",
       "422842  [(i, NNS), (have, VBP), (seen, VBN), (it, PRP)...  ...   \n",
       "422843  [(ok, IN), (so, RB), (i, JJ), (have, VBP), (ju...  ...   \n",
       "422844  [(i, NN), (would, MD), (never, RB), (want, VB)...  ...   \n",
       "\n",
       "        adjective_freq  adverb_freq  preposition_freq  interjection_freq  \\\n",
       "422840               4            3                 3                  0   \n",
       "422841               0            2                 1                  0   \n",
       "422842               2            5                 3                  0   \n",
       "422843               8            6                 3                  0   \n",
       "422844               1            3                 2                  0   \n",
       "\n",
       "        determiner_freq  negative_sentiment  neutral_sentiment  \\\n",
       "422840                2                0.00              0.829   \n",
       "422841                1                0.00              1.000   \n",
       "422842                3                0.00              0.928   \n",
       "422843                4                0.00              0.798   \n",
       "422844                1                0.12              0.880   \n",
       "\n",
       "        positive_sentiment  overall_sentiment  word_count  \n",
       "422840               0.171             0.7783          41  \n",
       "422841               0.000             0.0000          17  \n",
       "422842               0.072             0.3612          39  \n",
       "422843               0.202             0.8218          43  \n",
       "422844               0.000            -0.1182          23  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_posts_df_merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422845 entries, 0 to 422844\n",
      "Data columns (total 23 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   e_vs_i                   422845 non-null  object \n",
      " 1   s_vs_n                   422845 non-null  object \n",
      " 2   t_vs_f                   422845 non-null  object \n",
      " 3   j_vs_p                   422845 non-null  object \n",
      " 4   type                     422845 non-null  object \n",
      " 5   posts                    422845 non-null  object \n",
      " 6   url_count                422845 non-null  int64  \n",
      " 7   posts_no_url             422845 non-null  object \n",
      " 8   posts_no_url_tokenized   422845 non-null  object \n",
      " 9   posts_no_url_pos_tagged  422845 non-null  object \n",
      " 10  noun_freq                422845 non-null  int64  \n",
      " 11  verb_freq                422845 non-null  int64  \n",
      " 12  cardinal_digits_freq     422845 non-null  int64  \n",
      " 13  adjective_freq           422845 non-null  int64  \n",
      " 14  adverb_freq              422845 non-null  int64  \n",
      " 15  preposition_freq         422845 non-null  int64  \n",
      " 16  interjection_freq        422845 non-null  int64  \n",
      " 17  determiner_freq          422845 non-null  int64  \n",
      " 18  negative_sentiment       422845 non-null  float64\n",
      " 19  neutral_sentiment        422845 non-null  float64\n",
      " 20  positive_sentiment       422845 non-null  float64\n",
      " 21  overall_sentiment        422845 non-null  float64\n",
      " 22  word_count               422845 non-null  int64  \n",
      "dtypes: float64(4), int64(10), object(9)\n",
      "memory usage: 74.2+ MB\n"
     ]
    }
   ],
   "source": [
    "online_posts_df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE_CSV_PATH = os.path.join(\"data\", \"mbti_2.csv\")\n",
    "\n",
    "def write_csv_data(df: pd.DataFrame, csv_file_path: str = WRITE_CSV_PATH) -> pd.DataFrame:\n",
    "    \"\"\" Write data to from a given pandas DataFrame to the specifed csv file path.\n",
    "\n",
    "    Args:\n",
    "    - df (pandas DataFrame) - The DataFrame containing the data to wrtie to csv.\n",
    "    - csv_file_path (str) - The file path of the csv file to write data from the given pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    assert csv_file_path.endswith(\".csv\")\n",
    "\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv_data(online_posts_df_merged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_myers_briggs_personalities",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c5e62d055c9f5019009eeac34d5848eef589b72b0bbb976c58401fa648b29a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
