{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development\n",
    "\n",
    "Based on the previous work in the other notebooks, we managed to gain some initial insight for what might be contributing features when it comes to determining an online users MBTI personality factors based on what they posted, such as the overall sentiment of their posts, length of their posts, noun and verb frequency of their posts, etc. Here we try to develop a model with more emphasis on performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE + Word2Vec + Logistic Regression\n",
    "\n",
    "In the paper *Ryan, G.; Katarina, P.; Suhartono, D. MBTI Personality Prediction Using Machine Learning and SMOTE for Balancing Data Based on Statement Sentences. Information 2023, 14, 217*, a combination of SMOTE oversampling, Word2Vec word embeddings and Logistic Regression was used to achieve an average F1 - Score of 0.8337 across the four dimensions of MBTI personalities, namely:\n",
    "- Extraversion vs Introversion\n",
    "- Sensing vs Intuition\n",
    "- Thinking vs Feeling\n",
    "- Judgment vs Perception\n",
    "\n",
    "In this section we will attempt to implement this model from the paper using their methodology."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from itertools import zip_longest\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DATA_PATH = os.path.join(\"data\", \"mbti_1.csv\")\n",
    "\n",
    "def load_csv_data(csv_file_path: str):\n",
    "    \"\"\" Load data from a given csv file into a pandas DataFrame object.\n",
    "\n",
    "    Args:\n",
    "    - csv_file_path (str) - The file path of the csv file containing the desired data to load into a pandas DataFrame object.\n",
    "\n",
    "    Returns:\n",
    "    - data (pandas.DataFrame) - The loaded data as a pandas DataFrame object.\n",
    "    \"\"\"\n",
    "    assert csv_file_path.endswith(\".csv\")\n",
    "\n",
    "    return pd.read_csv(csv_file_path)\n",
    "\n",
    "def get_online_posts_df(df: pd.DataFrame, type_col: str = \"type\", posts_col: str = \"posts\"):\n",
    "    \"\"\" Takes in an input pandas DataFrame, each row having a (user_personality_type, user_recent_50_comments) schema and user_recent_50_comments is a '|||' delimited string.\n",
    "    Outputs a DataFrame object where each row is a (user_personality_type, user_comment), where each row no contains exactly one comment.\n",
    "\n",
    "    Args:\n",
    "    - df (pandas.DataFrame) - The input pandas DataFrame object, where each row follows the schema (user_personality_type, user_recent_50_comments).\n",
    "    - type_col (str) - The column name of the input DataFrame's personality type column, which contains the user's personality type.\n",
    "    - posts_col (str) - The column name of the input DataFrame's posts column, which contains the user's recent 50 comments/online posts\n",
    "\n",
    "    Returns:\n",
    "    - output_df (pandas.DataFrame) - The output pandas DataFrame object, where each row follows the schema (user_personality_type, user_comment).\n",
    "    \"\"\"\n",
    "    online_posts_dict = {\n",
    "        type_col: [],\n",
    "        posts_col: []\n",
    "    }\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        personality_type = row[type_col]\n",
    "        recent_50_comments = row[posts_col].split(\"|||\")\n",
    "\n",
    "        online_posts_dict[type_col] += [personality_type] * len(recent_50_comments)\n",
    "        online_posts_dict[posts_col] += recent_50_comments\n",
    "\n",
    "    columns = online_posts_dict.keys()\n",
    "    values = list(zip_longest(*online_posts_dict.values()))\n",
    "    output_df = pd.DataFrame(values, columns=columns)\n",
    "\n",
    "    return output_df\n",
    "\n",
    "def get_personality_dimensions(personality_dataset: pd.DataFrame, personalities_col_name: str = \"type\"):\n",
    "    \"\"\" Return a dictionary containing the personality dimensions from the given pandas DataFrame containing Myers Briggs personalities.\n",
    "\n",
    "    Args:\n",
    "    - personality_dataset (pandas.DataFrame) - The pandas DataFrame object containing the Myers Briggs personalities data.\n",
    "    - personalities_col_name (str) - The name of the column which contains the Myers Briggs personalities in the given DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - personality_factors_dict (dict) - A dictionary containing the number personality dimensions, split into Extraversion vs Introversion, Sensing vs Intuition, Thinking vs Feeling, Judging vs Perceiving.\n",
    "    \"\"\"\n",
    "    personality_factors_dict = {\n",
    "        \"e_vs_i\": [],\n",
    "        \"s_vs_n\": [],\n",
    "        \"t_vs_f\": [],\n",
    "        \"j_vs_p\": []\n",
    "    }\n",
    "\n",
    "    for index, row in personality_dataset.iterrows():\n",
    "        personality_type_str = row[personalities_col_name]\n",
    "        e_vs_i = personality_type_str[0]\n",
    "        s_vs_n = personality_type_str[1]\n",
    "        t_vs_f = personality_type_str[2]\n",
    "        j_vs_p = personality_type_str[3]\n",
    "\n",
    "        personality_factors_dict[\"e_vs_i\"].append(e_vs_i)\n",
    "        personality_factors_dict[\"s_vs_n\"].append(s_vs_n)\n",
    "        personality_factors_dict[\"t_vs_f\"].append(t_vs_f)\n",
    "        personality_factors_dict[\"j_vs_p\"].append(j_vs_p)\n",
    "\n",
    "    return personality_factors_dict  \n",
    "\n",
    "def preprocess_df(df: pd.DataFrame):\n",
    "    \"\"\" Helper function for preprocessing the input pandas dataframe by helping clean up input user posts.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame) - The input dataframe object containing the user posts to clean up.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame) - The given dataframe object after cleaning has been applied to the user posts data.\n",
    "    \"\"\"   \n",
    "\n",
    "    # Make each data record a user post rather than a user's top 50 posts.\n",
    "    df = get_online_posts_df(df)\n",
    "\n",
    "    # Extract the labels across the four dimensions of MBTI personalities corresponding to each post\n",
    "    personality_factors_per_post_dict = get_personality_dimensions(df)\n",
    "    columns = personality_factors_per_post_dict.keys()\n",
    "    values = list(zip_longest(*personality_factors_per_post_dict.values()))\n",
    "    personality_factors_per_post = pd.DataFrame(values, columns=columns)\n",
    "    df = pd.concat([personality_factors_per_post, df], axis=1)\n",
    "\n",
    "    # Remove urls\n",
    "    regex_pattern = r\"((?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’])))\"\n",
    "    df[\"posts_no_url\"] = df[\"posts\"].str.replace(regex_pattern, \"\").str.strip()\n",
    "\n",
    "    # Keep the End Of Sentence characters\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].apply(lambda x: re.sub(r'\\.', ' EOSTokenDot ', str(x) + \" \"))\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].apply(lambda x: re.sub(r'\\?', ' EOSTokenQuest ', str(x) + \" \"))\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].apply(lambda x: re.sub(r'!', ' EOSTokenExs ', str(x) + \" \"))\n",
    "    \n",
    "    # Strip Punctation\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].apply(lambda x: re.sub(r'[\\.+]', \".\", str(x)))\n",
    "\n",
    "    # Remove multiple fullstops\n",
    "    # df[\"posts_no_url\"] = df[\"posts_no_url\"].apply(lambda x: re.sub(r'[^\\w\\s]','', str(x)))\n",
    "\n",
    "    # Remove Non-words\n",
    "    # df[\"posts_no_url\"] = df[\"posts_no_url\"].apply(lambda x: re.sub(r'[^a-zA-Z\\s]','', str(x)))\n",
    "\n",
    "    # Convert posts to lowercase\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].apply(lambda x: str(x).lower())\n",
    "\n",
    "    # Remove multiple letter repeating words\n",
    "    # df[\"posts_no_url\"] = df[\"posts_no_url\"].apply(lambda x: re.sub(r'([a-z])\\1{2,}[\\s|\\w]*','', str(x)))\n",
    "    \n",
    "    # Strip trailing whitespaces\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].apply(lambda x: str(x).strip())\n",
    "\n",
    "    # Remove rows with no text\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].replace('', np.nan)\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].replace('nan', np.nan)\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].replace(\"'\", np.nan)\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].replace(\"''\", np.nan)\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].replace('\"', np.nan)\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].replace('\"\"', np.nan)\n",
    "    df.dropna(subset=[\"posts_no_url\"], inplace=True)\n",
    "\n",
    "    # Tokenize posts\n",
    "    df[\"posts_no_url_tokens\"] = df[\"posts_no_url\"].apply(wordpunct_tokenize)\n",
    "\n",
    "    # Remove stop words\n",
    "    df[\"posts_no_url_tokens_no_stop\"] = df[\"posts_no_url_tokens\"].apply(lambda x: [token for token in x if token not in stop_words])\n",
    "\n",
    "    # Lemmatize posts\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df[\"posts_no_url_tokens_no_stop\"] = df[\"posts_no_url_tokens_no_stop\"].apply(lambda x: [lemmatizer.lemmatize(token) for token in x])\n",
    "\n",
    "    return df[[\"e_vs_i\", \"s_vs_n\", \"t_vs_f\", \"j_vs_p\", \"type\", \"posts\", \"posts_no_url\", \"posts_no_url_tokens_no_stop\"]]\n",
    "\n",
    "def binarize_targets(df: pd.DataFrame):\n",
    "    \"\"\" Apply 0/1 labels to the input classes in the df.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame) - The input dataframe object containing the classes to numerically label.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame) - The given dataframe object after numerically labelling classes.\n",
    "    \"\"\"\n",
    "    binary_map = {\n",
    "        'I': 0, \n",
    "        'E': 1, \n",
    "        'N': 0, \n",
    "        'S': 1, \n",
    "        'F': 0, \n",
    "        'T': 1, \n",
    "        'J': 0, \n",
    "        'P': 1\n",
    "    }\n",
    "\n",
    "    df[\"EI\"] = df[\"e_vs_i\"].apply(lambda x: binary_map[str(x)])\n",
    "    df[\"SN\"] = df[\"s_vs_n\"].apply(lambda x: binary_map[str(x)])\n",
    "    df[\"TF\"] = df[\"t_vs_f\"].apply(lambda x: binary_map[str(x)])\n",
    "    df[\"JP\"] = df[\"j_vs_p\"].apply(lambda x: binary_map[str(x)])\n",
    "\n",
    "    df[\"target_vec\"] = df.apply(lambda x: [\n",
    "        x[\"EI\"],\n",
    "        x[\"SN\"],\n",
    "        x[\"TF\"],\n",
    "        x[\"JP\"]\n",
    "    ], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_dataset(csv_file_path: str = CSV_DATA_PATH):\n",
    "    \"\"\" Load and preprocess data to be used for model development.\n",
    "\n",
    "    Args:\n",
    "    - csv_file_path (str) - The file path of the csv file containing the desired data to load into a pandas DataFrame object.\n",
    "\n",
    "    Returns:\n",
    "    - numpy arrays of training and test split data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply preprocessing to input user posts\n",
    "    df = load_csv_data(csv_file_path)\n",
    "    df = preprocess_df(df)\n",
    "\n",
    "    # Preprocess target labels into a binary vector\n",
    "    df = binarize_targets(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_dataset()\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following preprocessing steps were applied to the dataset:\n",
    "- Converting letters to lowercase\n",
    "- Removing links\n",
    "- Removing punctuations\n",
    "- Removing stopwords\n",
    "\n",
    "Lematization was also applied after the above steps have been conducted, and the resulting text for each post tokenized."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word Embeddings and Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "w2w_model = Word2Vec(sentences=df[\"posts_no_url_tokens_no_stop\"], vector_size=500, window=5, min_count=5, epochs=50)\n",
    "\n",
    "def get_train_test_split(training_fraction: float, df: pd.DataFrame, mbti_dim: str):\n",
    "    \"\"\" Get a training and test dataset split.\n",
    "\n",
    "    Args:\n",
    "    - training_proportion (float) - The fraction of the dataset to be used as training data.\n",
    "    - df (pd.DataFrame) - The pandas dataframe object containing the data to be split into train and test sets.\n",
    "    - mbti_dim (str) - The column name of the target MBTI personality dimension.\n",
    "\n",
    "    Returns:\n",
    "    - Train and test datasets where the target variable is the desired MBTI personality dimension (mbti_dim).\n",
    "    \"\"\"\n",
    "\n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[\"posts_no_url_tokens_no_stop\"], df[mbti_dim], test_size=(1 - training_fraction), random_state=42)\n",
    "\n",
    "    X_train = np.array([vectorize(post) for post in X_train])\n",
    "    X_test = np.array([vectorize(post) for post in X_test])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def vectorize(post: list):\n",
    "    \"\"\" Vectorize a sentence to a vector representation using Word2Vec CBOW.\n",
    "\n",
    "    Args:\n",
    "    - post (str) - A post to vectorize. Here, the post is passed into the function as a list of word tokens.\n",
    "\n",
    "    Returns:\n",
    "    - Word2Vec word embedding (CBOW).\n",
    "    \"\"\"\n",
    "\n",
    "    # Vectorize sentence\n",
    "    words_vector = [w2w_model.wv[token] for token in post if token in w2w_model.wv]\n",
    "\n",
    "    if len(words_vector) == 0:\n",
    "        return np.zeros(500)\n",
    "    \n",
    "    words_vector = np.array(words_vector)\n",
    "    return words_vector.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_EI, X_test_EI, y_train_EI, y_test_EI = get_train_test_split(0.7, df, \"EI\") \n",
    "print(X_train_EI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_EI[160])\n",
    "print(type(X_test_EI))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create functionality that can split out user posts dataset into train and test sets, and vectorize the text data to be used as model inputs as Word2Vec word embeddings. The benefit with using word embeddings is that we can represent words in a numerical format (ML/DL models can only take in numerical input) that allows words with similar meanings to have the same representation, i.e. smilarity of meaning between words is captured in the word embeddings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, log_loss\n",
    "from sklearn.model_selection import LearningCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LR():\n",
    "    \"\"\" Create a simple Logistic Regression model on the given training data. \n",
    "    SMOTE oversampling will also performed when this model is fitted to training data.\n",
    "\n",
    "    Args:\n",
    "    - X (iterable) - Input training examples.\n",
    "    - y (iterable) - Training target labels.\n",
    "\n",
    "    Returns:\n",
    "    - The Logistic Regression model to be fitted onto training data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Instatiate SMOTE over-sampler and Logistic Regression model.\n",
    "    sampler = SMOTE(random_state=42)\n",
    "    lr = LogisticRegression(\n",
    "        penalty=None,\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Build pipeline/model.\n",
    "    pipeline = Pipeline([\n",
    "        (\"sampler\", sampler),\n",
    "        (\"lr\", lr)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "def train_model(X, y, model):\n",
    "    \"\"\" Train the input model on the given training data.\n",
    "\n",
    "    Args:\n",
    "    - X (iterable) - Input training examples.\n",
    "    - y (iterable) - Training target labels.\n",
    "    - model - The model to be fitted onto the training data.\n",
    "\n",
    "    Returns:\n",
    "    - The model fitted to the training data.\n",
    "    \"\"\"\n",
    "    model.fit(X, y)\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate(X, y, model, target_names):\n",
    "    \"\"\" Evaluate the given trained model on the test data.\n",
    "\n",
    "    Args:\n",
    "    - X (iterable) - Input test examples.\n",
    "    - y (iterable) - Test target labels.\n",
    "    - target_names - The names of the labels for the classfication report.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    print(classification_report(y, y_pred, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets for each MBTI dimension.\n",
    "X_train_EI, X_test_EI, y_train_EI, y_test_EI = get_train_test_split(0.7, df, \"EI\")\n",
    "X_train_SN, X_test_SN, y_train_SN, y_test_SN = get_train_test_split(0.7, df, \"SN\")\n",
    "X_train_TF, X_test_TF, y_train_TF, y_test_TF = get_train_test_split(0.7, df, \"TF\") \n",
    "X_train_JP, X_test_JP, y_train_JP, y_test_JP = get_train_test_split(0.7, df, \"JP\")\n",
    "\n",
    "# Create Logistic Regression classifiers for each MBTI dimension.\n",
    "ei_classifier = model_LR()\n",
    "sn_classifier = model_LR()\n",
    "tf_classifier = model_LR()\n",
    "jp_classifier = model_LR()\n",
    "\n",
    "# Train classifiers.\n",
    "ei_classifier = train_model(X_train_EI, y_train_EI, ei_classifier)\n",
    "sn_classifier = train_model(X_train_SN, y_train_SN, sn_classifier)\n",
    "tf_classifier = train_model(X_train_TF, y_train_TF, tf_classifier)\n",
    "jp_classifier = train_model(X_train_JP, y_train_JP, jp_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Extraversion vs Introversion classifier.\n",
    "evaluate(X_test_EI, y_test_EI, ei_classifier, [\"Introversion\", \"Extraversion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Sensing vs Intuition classifier.\n",
    "evaluate(X_test_SN, y_test_SN, sn_classifier, [\"Intuition\", \"Sensing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Thinking vs Feeling classifier.\n",
    "evaluate(X_test_TF, y_test_TF, tf_classifier, [\"Feeling\", \"Thinking\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Judging vs Perceiving classifier.\n",
    "evaluate(X_test_JP, y_test_JP, jp_classifier, [\"Judging\", \"Perceiving\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning cruves for the classifiers.\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Extraversion vs Introversion.\n",
    "X_EI = np.concatenate((X_train_EI, X_test_EI), axis=0)\n",
    "y_EI = np.concatenate((y_train_EI, y_test_EI), axis=0)\n",
    "model0 = model_LR()\n",
    "LearningCurveDisplay.from_estimator(model0, X_EI, y_EI, scoring=\"f1_macro\", score_name=\"F1 Macro Avg\", score_type=\"both\", n_jobs=4, line_kw={\"marker\": \"o\"}, random_state=42, ax=ax[0])\n",
    "handles0, label0 = ax[0].get_legend_handles_labels()\n",
    "ax[0].legend(handles0[:2], [\"Training Score\", \"Test Score\"])\n",
    "ax[0].set_title(\"Extraversion vs Introversion\")\n",
    "\n",
    "# Sensing vs Intuition.\n",
    "X_SN = np.concatenate((X_train_SN, X_test_SN), axis=0)\n",
    "y_SN = np.concatenate((y_train_SN, y_test_SN), axis=0)\n",
    "model1 = model_LR()\n",
    "LearningCurveDisplay.from_estimator(model1, X_SN, y_SN, scoring=\"f1_macro\", score_name=\"F1 Macro Avg\", score_type=\"both\", n_jobs=4, line_kw={\"marker\": \"o\"}, random_state=42, ax=ax[1])\n",
    "handles1, label1 = ax[1].get_legend_handles_labels()\n",
    "ax[1].legend(handles1[:2], [\"Training Score\", \"Test Score\"])\n",
    "ax[1].set_title(\"Sensing vs Intuition\")\n",
    "\n",
    "# Thinking vs Feeling.\n",
    "X_TF = np.concatenate((X_train_TF, X_test_TF), axis=0)\n",
    "y_TF = np.concatenate((y_train_TF, y_test_TF), axis=0)\n",
    "model2 = model_LR()\n",
    "LearningCurveDisplay.from_estimator(model2, X_TF, y_TF, scoring=\"f1_macro\", score_name=\"F1 Macro Avg\", score_type=\"both\", n_jobs=4, line_kw={\"marker\": \"o\"}, random_state=42, ax=ax[2])\n",
    "handles2, label2 = ax[2].get_legend_handles_labels()\n",
    "ax[2].legend(handles2[:2], [\"Training Score\", \"Test Score\"])\n",
    "ax[2].set_title(\"Thinking vs Feeling\")\n",
    "\n",
    "# Judging vs Perceiving.\n",
    "X_JP = np.concatenate((X_train_JP, X_test_JP), axis=0)\n",
    "y_JP = np.concatenate((y_train_JP, y_test_JP), axis=0)\n",
    "model3 = model_LR()\n",
    "LearningCurveDisplay.from_estimator(model3, X_JP, y_JP, scoring=\"f1_macro\", score_name=\"F1 Macro Avg\", score_type=\"both\", n_jobs=4, line_kw={\"marker\": \"o\"}, random_state=42, ax=ax[3])\n",
    "handles3, label3 = ax[3].get_legend_handles_labels()\n",
    "ax[3].legend(handles3[:2], [\"Training Score\", \"Test Score\"])\n",
    "ax[3].set_title(\"Judging vs Perceiving\")\n",
    "\n",
    "fig.suptitle(\"Learning Curves\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the classification reports we see that using the default parameter settings for logistic regression classifiers gives us an macro average F1 score in the 50s across the four dimensions of mbti personality. The learning curves above also show that overfitting might is not that big given the volume of posts we have in our dataset, however, it could also be the default L2 regularisation parameter of 10 in sklearn's Logistic Regression object.\n",
    "\n",
    "Now we will try to experiment with some different parameter settings to see if we can improve performance (with respect to macro average F1) and see if we can get closer to the performance acheived in the paper *Ryan, G.; Katarina, P.; Suhartono, D. MBTI Personality Prediction Using Machine Learning and SMOTE for Balancing Data Based on Statement Sentences. Information 2023, 14, 217*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LR_CV():\n",
    "    \"\"\" Create Logistic Regression model on the given training data. \n",
    "    \n",
    "    Cross Validation will be used to tune the hyperparameters of the model and SMOTE oversampling will also performed when this model is fitted to training data.\n",
    "\n",
    "    Args:\n",
    "    - X (iterable) - Input training examples.\n",
    "    - y (iterable) - Training target labels.\n",
    "\n",
    "    Returns:\n",
    "    - The Logistic Regression model to be fitted onto training data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Instatiate SMOTE over-sampler and Logistic Regression model.\n",
    "    sampler = SMOTE(random_state=42)\n",
    "    lr = LogisticRegressionCV(\n",
    "        Cs=[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        scoring=\"f1_macro\",\n",
    "        n_jobs=-1,\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Build pipeline/model.\n",
    "    pipeline = Pipeline([\n",
    "        (\"sampler\", sampler),\n",
    "        (\"lr\", lr)\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets for each MBTI dimension.\n",
    "X_train_EI, X_test_EI, y_train_EI, y_test_EI = get_train_test_split(0.7, df, \"EI\")\n",
    "X_train_SN, X_test_SN, y_train_SN, y_test_SN = get_train_test_split(0.7, df, \"SN\")\n",
    "X_train_TF, X_test_TF, y_train_TF, y_test_TF = get_train_test_split(0.7, df, \"TF\") \n",
    "X_train_JP, X_test_JP, y_train_JP, y_test_JP = get_train_test_split(0.7, df, \"JP\")\n",
    "\n",
    "# Create Logistic Regression classifiers for each MBTI dimension.\n",
    "ei_classifier = model_LR_CV()\n",
    "sn_classifier = model_LR_CV()\n",
    "tf_classifier = model_LR_CV()\n",
    "jp_classifier = model_LR_CV()\n",
    "\n",
    "# Train classifiers.\n",
    "ei_classifier = train_model(X_train_EI, y_train_EI, ei_classifier)\n",
    "sn_classifier = train_model(X_train_SN, y_train_SN, sn_classifier)\n",
    "tf_classifier = train_model(X_train_TF, y_train_TF, tf_classifier)\n",
    "jp_classifier = train_model(X_train_JP, y_train_JP, jp_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Extraversion vs Introversion classifier.\n",
    "evaluate(X_test_EI, y_test_EI, ei_classifier, [\"Introversion\", \"Extraversion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Sensing vs Intuition classifier.\n",
    "evaluate(X_test_SN, y_test_SN, sn_classifier, [\"Intuition\", \"Sensing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Thinking vs Feeling classifier.\n",
    "evaluate(X_test_TF, y_test_TF, tf_classifier, [\"Feeling\", \"Thinking\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Judging vs Perceiving classifier.\n",
    "evaluate(X_test_JP, y_test_JP, jp_classifier, [\"Judging\", \"Perceiving\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning cruves for the classifiers.\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Extraversion vs Introversion.\n",
    "X_EI = np.concatenate((X_train_EI, X_test_EI), axis=0)\n",
    "y_EI = np.concatenate((y_train_EI, y_test_EI), axis=0)\n",
    "model0 = model_LR()\n",
    "LearningCurveDisplay.from_estimator(model0, X_EI, y_EI, scoring=\"f1_macro\", score_name=\"F1 Macro Avg\", score_type=\"both\", n_jobs=4, line_kw={\"marker\": \"o\"}, random_state=42, ax=ax[0])\n",
    "handles0, label0 = ax[0].get_legend_handles_labels()\n",
    "ax[0].legend(handles0[:2], [\"Training Score\", \"Test Score\"])\n",
    "ax[0].set_title(\"Extraversion vs Introversion\")\n",
    "\n",
    "# Sensing vs Intuition.\n",
    "X_SN = np.concatenate((X_train_SN, X_test_SN), axis=0)\n",
    "y_SN = np.concatenate((y_train_SN, y_test_SN), axis=0)\n",
    "model1 = model_LR()\n",
    "LearningCurveDisplay.from_estimator(model1, X_SN, y_SN, scoring=\"f1_macro\", score_name=\"F1 Macro Avg\", score_type=\"both\", n_jobs=4, line_kw={\"marker\": \"o\"}, random_state=42, ax=ax[1])\n",
    "handles1, label1 = ax[1].get_legend_handles_labels()\n",
    "ax[1].legend(handles1[:2], [\"Training Score\", \"Test Score\"])\n",
    "ax[1].set_title(\"Sensing vs Intuition\")\n",
    "\n",
    "# Thinking vs Feeling.\n",
    "X_TF = np.concatenate((X_train_TF, X_test_TF), axis=0)\n",
    "y_TF = np.concatenate((y_train_TF, y_test_TF), axis=0)\n",
    "model2 = model_LR()\n",
    "LearningCurveDisplay.from_estimator(model2, X_TF, y_TF, scoring=\"f1_macro\", score_name=\"F1 Macro Avg\", score_type=\"both\", n_jobs=4, line_kw={\"marker\": \"o\"}, random_state=42, ax=ax[2])\n",
    "handles2, label2 = ax[2].get_legend_handles_labels()\n",
    "ax[2].legend(handles2[:2], [\"Training Score\", \"Test Score\"])\n",
    "ax[2].set_title(\"Thinking vs Feeling\")\n",
    "\n",
    "# Judging vs Perceiving.\n",
    "X_JP = np.concatenate((X_train_JP, X_test_JP), axis=0)\n",
    "y_JP = np.concatenate((y_train_JP, y_test_JP), axis=0)\n",
    "model3 = model_LR()\n",
    "LearningCurveDisplay.from_estimator(model3, X_JP, y_JP, scoring=\"f1_macro\", score_name=\"F1 Macro Avg\", score_type=\"both\", n_jobs=4, line_kw={\"marker\": \"o\"}, random_state=42, ax=ax[3])\n",
    "handles3, label3 = ax[3].get_legend_handles_labels()\n",
    "ax[3].legend(handles3[:2], [\"Training Score\", \"Test Score\"])\n",
    "ax[3].set_title(\"Judging vs Perceiving\")\n",
    "\n",
    "fig.suptitle(\"Learning Curves\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network\n",
    "\n",
    "In the paper *Sakdipat Ontoum, Jonathan H. Chan. Personality Type Based on Myers-Briggs Type Indicator with Text Posting Style by using Traditional and Deep Learning. https://doi.org/10.48550/arXiv.2201.08717*, they acheived a macro average F1 score of 80+ across the following MBTI dimensions using a recurrent neural network:\n",
    "- Extraversion vs Introversion\n",
    "- Sensing vs Intuition\n",
    "- Thinking vs Feeling\n",
    "- Judgment vs Perception\n",
    "\n",
    "In this section we will attempt to implement this model from the paper and see if we can achieve better results than the model used in the feature engineering notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\stefa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from itertools import zip_longest\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DATA_PATH = os.path.join(\"data\", \"mbti_1.csv\")\n",
    "\n",
    "def load_csv_data(csv_file_path: str):\n",
    "    \"\"\" Load data from a given csv file into a pandas DataFrame object.\n",
    "\n",
    "    Args:\n",
    "    - csv_file_path (str) - The file path of the csv file containing the desired data to load into a pandas DataFrame object.\n",
    "\n",
    "    Returns:\n",
    "    - data (pandas.DataFrame) - The loaded data as a pandas DataFrame object.\n",
    "    \"\"\"\n",
    "    assert csv_file_path.endswith(\".csv\")\n",
    "\n",
    "    return pd.read_csv(csv_file_path)\n",
    "\n",
    "def get_online_posts_df(df: pd.DataFrame, type_col: str = \"type\", posts_col: str = \"posts\"):\n",
    "    \"\"\" Takes in an input pandas DataFrame, each row having a (user_personality_type, user_recent_50_comments) schema and user_recent_50_comments is a '|||' delimited string.\n",
    "    Outputs a DataFrame object where each row is a (user_personality_type, user_comment), where each row no contains exactly one comment.\n",
    "\n",
    "    Args:\n",
    "    - df (pandas.DataFrame) - The input pandas DataFrame object, where each row follows the schema (user_personality_type, user_recent_50_comments).\n",
    "    - type_col (str) - The column name of the input DataFrame's personality type column, which contains the user's personality type.\n",
    "    - posts_col (str) - The column name of the input DataFrame's posts column, which contains the user's recent 50 comments/online posts\n",
    "\n",
    "    Returns:\n",
    "    - output_df (pandas.DataFrame) - The output pandas DataFrame object, where each row follows the schema (user_personality_type, user_comment).\n",
    "    \"\"\"\n",
    "    online_posts_dict = {\n",
    "        type_col: [],\n",
    "        posts_col: []\n",
    "    }\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        personality_type = row[type_col]\n",
    "        recent_50_comments = row[posts_col].split(\"|||\")\n",
    "\n",
    "        online_posts_dict[type_col] += [personality_type] * len(recent_50_comments)\n",
    "        online_posts_dict[posts_col] += recent_50_comments\n",
    "\n",
    "    columns = online_posts_dict.keys()\n",
    "    values = list(zip_longest(*online_posts_dict.values()))\n",
    "    output_df = pd.DataFrame(values, columns=columns)\n",
    "\n",
    "    return output_df\n",
    "\n",
    "def get_personality_dimensions(personality_dataset: pd.DataFrame, personalities_col_name: str = \"type\"):\n",
    "    \"\"\" Return a dictionary containing the personality dimensions from the given pandas DataFrame containing Myers Briggs personalities.\n",
    "\n",
    "    Args:\n",
    "    - personality_dataset (pandas.DataFrame) - The pandas DataFrame object containing the Myers Briggs personalities data.\n",
    "    - personalities_col_name (str) - The name of the column which contains the Myers Briggs personalities in the given DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - personality_factors_dict (dict) - A dictionary containing the number personality dimensions, split into Extraversion vs Introversion, Sensing vs Intuition, Thinking vs Feeling, Judging vs Perceiving.\n",
    "    \"\"\"\n",
    "    personality_factors_dict = {\n",
    "        \"e_vs_i\": [],\n",
    "        \"s_vs_n\": [],\n",
    "        \"t_vs_f\": [],\n",
    "        \"j_vs_p\": []\n",
    "    }\n",
    "\n",
    "    for index, row in personality_dataset.iterrows():\n",
    "        personality_type_str = row[personalities_col_name]\n",
    "        e_vs_i = personality_type_str[0]\n",
    "        s_vs_n = personality_type_str[1]\n",
    "        t_vs_f = personality_type_str[2]\n",
    "        j_vs_p = personality_type_str[3]\n",
    "\n",
    "        personality_factors_dict[\"e_vs_i\"].append(e_vs_i)\n",
    "        personality_factors_dict[\"s_vs_n\"].append(s_vs_n)\n",
    "        personality_factors_dict[\"t_vs_f\"].append(t_vs_f)\n",
    "        personality_factors_dict[\"j_vs_p\"].append(j_vs_p)\n",
    "\n",
    "    return personality_factors_dict  \n",
    "\n",
    "def preprocess_df(df: pd.DataFrame):\n",
    "    \"\"\" Helper function for preprocessing the input pandas dataframe by helping clean up input user posts.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame) - The input dataframe object containing the user posts to clean up.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame) - The given dataframe object after cleaning has been applied to the user posts data.\n",
    "    \"\"\"   \n",
    "\n",
    "    # Make each data record a user post rather than a user's top 50 posts.\n",
    "    df = get_online_posts_df(df)\n",
    "\n",
    "    # Extract the labels across the four dimensions of MBTI personalities corresponding to each post\n",
    "    personality_factors_per_post_dict = get_personality_dimensions(df)\n",
    "    columns = personality_factors_per_post_dict.keys()\n",
    "    values = list(zip_longest(*personality_factors_per_post_dict.values()))\n",
    "    personality_factors_per_post = pd.DataFrame(values, columns=columns)\n",
    "    df = pd.concat([personality_factors_per_post, df], axis=1)\n",
    "\n",
    "    # Remove urls\n",
    "    regex_pattern = r\"((?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’])))\"\n",
    "    df[\"posts_no_url\"] = df[\"posts\"].str.replace(regex_pattern, \"\").str.strip()\n",
    "\n",
    "    # Keep the End Of Sentence characters\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].apply(lambda x: re.sub(r'\\.', ' EOSTokenDot ', str(x) + \" \"))\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].apply(lambda x: re.sub(r'\\?', ' EOSTokenQuest ', str(x) + \" \"))\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].apply(lambda x: re.sub(r'!', ' EOSTokenExs ', str(x) + \" \"))\n",
    "\n",
    "    # Strip trailing whitespaces\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].apply(lambda x: str(x).strip())\n",
    "\n",
    "    # Tokenize posts\n",
    "    df[\"posts_no_url_tokens\"] = df[\"posts_no_url\"].apply(word_tokenize)\n",
    "\n",
    "    # Remove stop words\n",
    "    df[\"posts_no_url_tokens_no_stop\"] = df[\"posts_no_url_tokens\"].apply(lambda x: [token for token in x if token not in stop_words])\n",
    "\n",
    "    # Lemmatize posts\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df[\"posts_no_url_tokens_no_stop\"] = df[\"posts_no_url_tokens_no_stop\"].apply(lambda x: [lemmatizer.lemmatize(token) for token in x])\n",
    "\n",
    "    # Remove rows with no text\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].replace('nan', np.nan)\n",
    "    df[\"posts_no_url\"] = df[\"posts_no_url\"].replace('', np.nan)\n",
    "    df.dropna(subset=[\"posts_no_url\"], inplace=True)\n",
    "\n",
    "    # Create column for preprocessed posts\n",
    "    df[\"preprocessed_posts\"] = df[\"posts_no_url_tokens_no_stop\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    return df[[\"e_vs_i\", \"s_vs_n\", \"t_vs_f\", \"j_vs_p\", \"type\", \"posts\", \"preprocessed_posts\"]]\n",
    "\n",
    "def binarize_targets(df: pd.DataFrame):\n",
    "    \"\"\" Apply 0/1 labels to the input classes in the df.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame) - The input dataframe object containing the classes to numerically label.\n",
    "\n",
    "    Returns:\n",
    "    - df (pd.DataFrame) - The given dataframe object after numerically labelling classes.\n",
    "    \"\"\"\n",
    "    binary_map = {\n",
    "        'I': 0, \n",
    "        'E': 1, \n",
    "        'N': 0, \n",
    "        'S': 1, \n",
    "        'F': 0, \n",
    "        'T': 1, \n",
    "        'J': 0, \n",
    "        'P': 1\n",
    "    }\n",
    "\n",
    "    df[\"EI\"] = df[\"e_vs_i\"].apply(lambda x: binary_map[str(x)])\n",
    "    df[\"SN\"] = df[\"s_vs_n\"].apply(lambda x: binary_map[str(x)])\n",
    "    df[\"TF\"] = df[\"t_vs_f\"].apply(lambda x: binary_map[str(x)])\n",
    "    df[\"JP\"] = df[\"j_vs_p\"].apply(lambda x: binary_map[str(x)])\n",
    "\n",
    "    df[\"target_vec\"] = df.apply(lambda x: [\n",
    "        x[\"EI\"],\n",
    "        x[\"SN\"],\n",
    "        x[\"TF\"],\n",
    "        x[\"JP\"]\n",
    "    ], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_dataset(csv_file_path: str = CSV_DATA_PATH):\n",
    "    \"\"\" Load and preprocess data to be used for model development.\n",
    "\n",
    "    Args:\n",
    "    - csv_file_path (str) - The file path of the csv file containing the desired data to load into a pandas DataFrame object.\n",
    "\n",
    "    Returns:\n",
    "    - numpy arrays of training and test split data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply preprocessing to input user posts\n",
    "    df = load_csv_data(csv_file_path)\n",
    "    df = preprocess_df(df)\n",
    "\n",
    "    # Preprocess target labels into a binary vector\n",
    "    df = binarize_targets(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stefa\\AppData\\Local\\Temp\\ipykernel_8624\\1312023727.py:99: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"posts_no_url\"] = df[\"posts\"].str.replace(regex_pattern, \"\").str.strip()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_vs_i</th>\n",
       "      <th>s_vs_n</th>\n",
       "      <th>t_vs_f</th>\n",
       "      <th>j_vs_p</th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>preprocessed_posts</th>\n",
       "      <th>EI</th>\n",
       "      <th>SN</th>\n",
       "      <th>TF</th>\n",
       "      <th>JP</th>\n",
       "      <th>target_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw</td>\n",
       "      <td>'</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  https://www.youtube.com...</td>\n",
       "      <td>enfp intj moment sportscenter top ten play prank</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>What life-changing experience life EOSTokenQuest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://www.youtube.com/watch?v=vXZeYwwRDw8   h...</td>\n",
       "      <td>On repeat today EOSTokenDot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>May the PerC Experience immerse you.</td>\n",
       "      <td>May PerC Experience immerse EOSTokenDot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  e_vs_i s_vs_n t_vs_f j_vs_p  type  \\\n",
       "0      I      N      F      J  INFJ   \n",
       "2      I      N      F      J  INFJ   \n",
       "3      I      N      F      J  INFJ   \n",
       "4      I      N      F      J  INFJ   \n",
       "5      I      N      F      J  INFJ   \n",
       "\n",
       "                                               posts  \\\n",
       "0        'http://www.youtube.com/watch?v=qsXHcwe3krw   \n",
       "2  enfp and intj moments  https://www.youtube.com...   \n",
       "3  What has been the most life-changing experienc...   \n",
       "4  http://www.youtube.com/watch?v=vXZeYwwRDw8   h...   \n",
       "5               May the PerC Experience immerse you.   \n",
       "\n",
       "                                 preprocessed_posts  EI  SN  TF  JP  \\\n",
       "0                                                 '   0   0   0   0   \n",
       "2  enfp intj moment sportscenter top ten play prank   0   0   0   0   \n",
       "3  What life-changing experience life EOSTokenQuest   0   0   0   0   \n",
       "4                       On repeat today EOSTokenDot   0   0   0   0   \n",
       "5           May PerC Experience immerse EOSTokenDot   0   0   0   0   \n",
       "\n",
       "     target_vec  \n",
       "0  [0, 0, 0, 0]  \n",
       "2  [0, 0, 0, 0]  \n",
       "3  [0, 0, 0, 0]  \n",
       "4  [0, 0, 0, 0]  \n",
       "5  [0, 0, 0, 0]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocess_dataset()\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following preprocessing steps were applied to the dataset:\n",
    "- Removing links\n",
    "- Removing stopwords\n",
    "- Lemmatization of text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_myers_briggs_personalities",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
